{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-04T04:02:50.929091Z",
     "start_time": "2024-09-04T04:01:34.157924Z"
    }
   },
   "source": [
    "# from wordcloud import WordCloud\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    " \n",
    "path = \"C:\\\\workspace\\\\특화프로젝트\\\\chromedriver-win64\\\\chromedriver.exe\" # 웹드라이버 실행\n",
    " \n",
    "driver = webdriver.Chrome() # 드라이버 경로 설정\n",
    "url_list = [] # url을 저장하기 위한 변수\n",
    "content_list = []\n",
    "\n",
    "cat_values = [\"111\", \"115\", \"116\"]\n",
    "\n",
    "def collect_urls_for_cat(cat):\n",
    "    for i in range(1, 11):  \n",
    "        url = f'https://kid.chosun.com/list_kj.html?catid={cat}&pn={i}'\n",
    "        driver.get(url)\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        for j in range(1, 11): \n",
    "            try:\n",
    "                title_element = driver.find_element(By.XPATH, f'//*[@id=\"container\"]/section[2]/article/ul/li[{j}]/div[2]/div[1]/a ')\n",
    "                title_url = title_element.get_attribute('href')\n",
    "                url_list.append(title_url)\n",
    "            except Exception as e:\n",
    "                print(f\"Error finding element: {e}\")  \n",
    "                       \n",
    "        \n",
    "for cat in cat_values:\n",
    "    collect_urls_for_cat(cat)\n",
    "        \n",
    "print(\"url 수집 끝\")\n",
    "driver.close()\n",
    "\n",
    "print(\"수집한 url 개수 : \"+str(len(url_list)))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url 수집 끝\n",
      "수집한 url 개수 : 300\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T04:23:47.406312Z",
     "start_time": "2024-09-04T04:11:42.317333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "df = pd.DataFrame(columns=['URL', 'title', 'content']) # content를 누적하기 위한 변수\n",
    "\n",
    "for index, url in enumerate(url_list):\n",
    "    level_text = \"\"\n",
    "    title_text = \"\"\n",
    "    content_text = \"\"\n",
    "    question_text = \"\"\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "    title = soup.find('div', class_='page_title_subject')\n",
    "    if title:\n",
    "        title_text = title.get_text(strip=True)\n",
    "    else:\n",
    "        title_text = \"No Title Found\"\n",
    "        \n",
    "    content_divs = soup.find_all('div', class_='Paragraph')\n",
    "    for div in content_divs:\n",
    "        paragraphs = div.find_all('p')\n",
    "        for paragraph in paragraphs:\n",
    "            content_text += paragraph.get_text().strip() + \"\\n\"\n",
    "        content_text += div.get_text().strip() + \"\\n\"\n",
    "\n",
    "    # Append the extracted content to the list\n",
    "    content_list.append({\n",
    "        'URL': url,\n",
    "        'title': title_text,\n",
    "        'content': content_text\n",
    "    })\n",
    "    \n",
    "    if (index + 1) % 50 == 0:\n",
    "        print(f\"Processed {index + 1} URLs\")\n",
    "\n",
    "# Convert to a DataFrame for easier handling\n",
    "df = pd.DataFrame(content_list)\n",
    "print(df)\n",
    "\n",
    "driver.quit()"
   ],
   "id": "3aef8bcb29ec40d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 50 URLs\n",
      "Processed 100 URLs\n",
      "Processed 150 URLs\n",
      "Processed 200 URLs\n",
      "Processed 250 URLs\n",
      "Processed 300 URLs\n",
      "                                                   URL  \\\n",
      "0    https://kid.chosun.com/site/data/html_dir/2024...   \n",
      "1    https://kid.chosun.com/site/data/html_dir/2024...   \n",
      "2    https://kid.chosun.com/site/data/html_dir/2024...   \n",
      "3    https://kid.chosun.com/site/data/html_dir/2024...   \n",
      "4    https://kid.chosun.com/site/data/html_dir/2024...   \n",
      "..                                                 ...   \n",
      "295  https://kid.chosun.com/site/data/html_dir/2022...   \n",
      "296  https://kid.chosun.com/site/data/html_dir/2022...   \n",
      "297  https://kid.chosun.com/site/data/html_dir/2022...   \n",
      "298  https://kid.chosun.com/site/data/html_dir/2022...   \n",
      "299  https://kid.chosun.com/site/data/html_dir/2022...   \n",
      "\n",
      "                                                 title  \\\n",
      "0                [초·저 / 동식물 이야기] 비단뱀, 큰 먹이 삼키면 심장 커진대요   \n",
      "1    [초·고 / 지구를 지켜줘] 중국이 양쯔강 싼샤댐 방류했더니 제주도 물고기가 다른 ...   \n",
      "2        [초·고 / 동식물 이야기] 산왕거미, 반딧불이 짝짓기 방법 이용해 먹이 구한대요   \n",
      "3    [초·고 / 시사체크! 키워드 / 님비와 핌피] 日 마이시마 소각장, 놀이동산처럼 ...   \n",
      "4       [초·저 / 동식물 이야기] 똑같아 보이는 꿀벌과 말벌… 독침 쏘는 건 어느 쪽일까   \n",
      "..                                                 ...   \n",
      "295                                손흥민 부상당한 ‘안와골’은 어디?   \n",
      "296                               [두근두근 사다리 게임] 달콤한 간식   \n",
      "297                                    야구 ‘과학의 눈’으로 보다   \n",
      "298                                  야구 용어 알고 보면 더 재밌다   \n",
      "299               [Dancing with Sports] 동작을 골고루 연결해봅시다   \n",
      "\n",
      "                                               content  \n",
      "0    ▲ 8월 22일(현지 시각) 미국 볼더 콜로라도대 연구팀은 비단뱀이 자기 몸집보다 ...  \n",
      "1    ▲ 폭우로 양쯔강 상류 수위가 높아지자, 7월 중국이 싼샤댐을 방류했다. 사진은 2...  \n",
      "2    ▲ 산왕거미가 거미줄에 걸린 수컷 반딧불이를 거미줄로 감싸는 모습. /Xinhua ...  \n",
      "3    ▲ 일본 오사카에 있는 마이시마 소각장. /위키미디어커먼스\\n▲ 2024년 6월 1...  \n",
      "4    ▲ 꿀벌(왼쪽)과 말벌. /위키미디어커먼스\\n\\n\\n                 ...  \n",
      "..                                                 ...  \n",
      "295  ▲ 11월 1일(현지 시각), 경기 중 부상당한 손흥민 선수가 응급 처치를 받고 있...  \n",
      "296  골라 골라~~. 한 개만 골라도 좋고 전부 다 골라도 돼요. '엉뚱 발랄한' 사다리...  \n",
      "297  2022 KBO 한국 시리즈가 막을 올렸어요. 사회적 거리 두기가 완전히 해제된 이...  \n",
      "298  ▲ /조선일보DB\\n\\n\\n                            야구는...  \n",
      "299  여덟 번째 발레 수업에 오신 걸 환영합니다. 오늘은 지난 시간까지 배운 동작들을 골...  \n",
      "\n",
      "[300 rows x 3 columns]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T04:25:42.043007Z",
     "start_time": "2024-09-04T04:25:42.024485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_path = \"data/raw/news/news_chosun_crawled.csv\"\n",
    "df.to_csv(file_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"Data saved\")"
   ],
   "id": "c32e7ba814421b62",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
